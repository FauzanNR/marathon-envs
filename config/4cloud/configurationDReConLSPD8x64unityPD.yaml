default_settings: null
behaviors:
  default:
    trainer_type: ppo
    hyperparameters:
      batch_size: 2048
      buffer_size: 20480
      learning_rate: 0.0001
      beta: 0.009
      epsilon: 0.2
      lambd: 0.95
      num_epoch: 3
      learning_rate_schedule: linear
    network_settings:
      normalize: true
      hidden_units: 512
      num_layers: 2
      vis_encode_type: simple
      memory: null
    reward_signals:
      extrinsic:
        gamma: 0.99
        strength: 1.0
    init_path: null
    keep_checkpoints: 5
    checkpoint_interval: 5000000
    max_steps: 128000000
    time_horizon: 1000
    summary_freq: 100000
    threaded: true
    self_play: null
    behavioral_cloning: null
    framework: pytorch
  DReCon-v0:
    trainer_type: ppo
    hyperparameters:
        num_epoch: 3
        beta: 9e-3
        learning_rate: 1e-4
        batch_size: 2048 
        buffer_size: 20480 # 768 * 4
    summary_freq: 100000
    checkpoint_interval: 5000000
    network_settings:
        num_layers: 2
        hidden_units: 512    
        normalize: true
    max_steps: 128e6
    time_horizon: 1000

env_settings:
  env_args:
  - --spawn-env=DReConUnityPD
  - --num-spawn-envs=64
  base_port: 5005
  num_envs: 8 
engine_settings:
  no_graphics: true
debug: false
